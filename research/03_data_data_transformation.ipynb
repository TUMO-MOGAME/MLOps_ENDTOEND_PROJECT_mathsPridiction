{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72748122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e806394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\ALL_FROM_DESKTOP\\\\Data_Science_ENDtoEND proj\\\\proj_1\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e660b178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\ALL_FROM_DESKTOP\\\\Data_Science_ENDtoEND proj\\\\proj_1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "%pwd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90707b7",
   "metadata": {},
   "source": [
    "# **Entity/init.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec56f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mathematicsScore.logging import logger\n",
    "from src.mathematicsScore.constants import *\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    transformed_train_path: Path\n",
    "    transformed_test_path: Path\n",
    "    preprocessor_path: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5d20463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mathematicsScore.constants import *\n",
    "from src.mathematicsScore.utils.common import read_yaml, create_directories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5f2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigarationManagementer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            transformed_train_path=config.transformed_train_path,\n",
    "            transformed_test_path=config.transformed_test_path,\n",
    "            preprocessor_path=config.preprocessor_path\n",
    "        )\n",
    "\n",
    "        return data_transformation_config\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72199218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.mathematicsScore.logging import logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47e53ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from src.mathematicsScore.logging import logger\n",
    "from src.mathematicsScore.entity import DataTransformationConfig\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config    \n",
    "        \n",
    "    def handle_missing_values(self, data):\n",
    "        \"\"\"\n",
    "        Handle missing values in the dataset. \n",
    "        Numerical columns will be filled with the median, \n",
    "        categorical columns will be filled with the mode.\n",
    "        \"\"\"\n",
    "        # Fill missing values for numerical columns with the median\n",
    "        numerical_columns = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "        for col in numerical_columns:\n",
    "            data[col].fillna(data[col].median(), inplace=True)\n",
    "        \n",
    "        # Fill missing values for categorical columns with the mode\n",
    "        categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "        for col in categorical_columns:\n",
    "            if not data[col].mode().empty:\n",
    "                data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def create_dummy_variables(self, data):\n",
    "        \"\"\"\n",
    "        Convert categorical variables into dummy variables (one-hot encoding).\n",
    "        \"\"\"\n",
    "        return pd.get_dummies(data, drop_first=True)\n",
    "    \n",
    "    def transform(self):\n",
    "        \"\"\"\n",
    "        Perform data transformation steps on pre-split train and test datasets.\n",
    "        Loads existing train_data.csv and test_data.csv, transforms them separately.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load the pre-split train and test data\n",
    "            train_data_path = os.path.join(\"artifacts/data_ingestion\", \"train_data.csv\")\n",
    "            test_data_path = os.path.join(\"artifacts/data_ingestion\", \"test_data.csv\")\n",
    "\n",
    "            logger.info(f\"Loading train data from {train_data_path}\")\n",
    "            train_data = pd.read_csv(train_data_path)\n",
    "            logger.info(f\"Train data loaded successfully with shape: {train_data.shape}\")\n",
    "\n",
    "            logger.info(f\"Loading test data from {test_data_path}\")\n",
    "            test_data = pd.read_csv(test_data_path)\n",
    "            logger.info(f\"Test data loaded successfully with shape: {test_data.shape}\")\n",
    "\n",
    "            # Transform train data\n",
    "            logger.info(\"Transforming train data...\")\n",
    "            train_data = self.handle_missing_values(train_data)\n",
    "            train_data = self.create_dummy_variables(train_data)\n",
    "\n",
    "            # Transform test data using the same transformations\n",
    "            logger.info(\"Transforming test data...\")\n",
    "            test_data = self.handle_missing_values(test_data)\n",
    "            test_data = self.create_dummy_variables(test_data)\n",
    "\n",
    "            # Ensure both datasets have the same columns (important for dummy variables)\n",
    "            # Get all columns from train data\n",
    "            train_columns = set(train_data.columns)\n",
    "            test_columns = set(test_data.columns)\n",
    "\n",
    "            # Add missing columns to test data (fill with 0)\n",
    "            missing_in_test = train_columns - test_columns\n",
    "            for col in missing_in_test:\n",
    "                test_data[col] = 0\n",
    "                logger.info(f\"Added missing column '{col}' to test data\")\n",
    "\n",
    "            # Add missing columns to train data (fill with 0)\n",
    "            missing_in_train = test_columns - train_columns\n",
    "            for col in missing_in_train:\n",
    "                train_data[col] = 0\n",
    "                logger.info(f\"Added missing column '{col}' to train data\")\n",
    "\n",
    "            # Reorder columns to match\n",
    "            train_data = train_data[sorted(train_data.columns)]\n",
    "            test_data = test_data[sorted(test_data.columns)]\n",
    "\n",
    "            # Save transformed data\n",
    "            logger.info(f\"Saving transformed train data to {self.config.transformed_train_path}\")\n",
    "            train_data.to_csv(self.config.transformed_train_path, index=False)\n",
    "\n",
    "            logger.info(f\"Saving transformed test data to {self.config.transformed_test_path}\")\n",
    "            test_data.to_csv(self.config.transformed_test_path, index=False)\n",
    "\n",
    "            # Save preprocessor info (for future use)\n",
    "            preprocessor_info = {\n",
    "                'feature_columns': list(train_data.columns),\n",
    "                'target_column': 'math_score' if 'math_score' in train_data.columns else None,\n",
    "                'train_shape': train_data.shape,\n",
    "                'test_shape': test_data.shape,\n",
    "                'original_train_shape': (train_data.shape[0], len(pd.read_csv(train_data_path).columns)),\n",
    "                'original_test_shape': (test_data.shape[0], len(pd.read_csv(test_data_path).columns))\n",
    "            }\n",
    "\n",
    "            with open(self.config.preprocessor_path, 'wb') as f:\n",
    "                pickle.dump(preprocessor_info, f)\n",
    "\n",
    "            logger.info(f\"Data transformation completed successfully\")\n",
    "            logger.info(f\"Transformed train data shape: {train_data.shape}\")\n",
    "            logger.info(f\"Transformed test data shape: {test_data.shape}\")\n",
    "\n",
    "            return {\n",
    "                'train_data': train_data,\n",
    "                'test_data': test_data,\n",
    "                'preprocessor_info': preprocessor_info\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in data transformation: {e}\")\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042cb9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tumom\\AppData\\Local\\Temp\\ipykernel_22436\\4095837263.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].median(), inplace=True)\n",
      "C:\\Users\\tumom\\AppData\\Local\\Temp\\ipykernel_22436\\4095837263.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].median(), inplace=True)\n",
      "C:\\Users\\tumom\\AppData\\Local\\Temp\\ipykernel_22436\\4095837263.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].median(), inplace=True)\n",
      "C:\\Users\\tumom\\AppData\\Local\\Temp\\ipykernel_22436\\4095837263.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].mode()[0], inplace=True)\n",
      "C:\\Users\\tumom\\AppData\\Local\\Temp\\ipykernel_22436\\4095837263.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].median(), inplace=True)\n",
      "C:\\Users\\tumom\\AppData\\Local\\Temp\\ipykernel_22436\\4095837263.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].median(), inplace=True)\n",
      "C:\\Users\\tumom\\AppData\\Local\\Temp\\ipykernel_22436\\4095837263.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].median(), inplace=True)\n",
      "C:\\Users\\tumom\\AppData\\Local\\Temp\\ipykernel_22436\\4095837263.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from src.mathematicsScore.config.configuration import ConfigurationManager\n",
    "\n",
    "def main(self):\n",
    "        try:\n",
    "            config = ConfigurationManager()\n",
    "            data_transformation_config = config.get_data_transformation_config()\n",
    "            data_transformation = DataTransformation(config=data_transformation_config)\n",
    "            result = data_transformation.transform()\n",
    "            logger.info(\"Data transformation completed successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in data transformation pipeline: {e}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea45a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
